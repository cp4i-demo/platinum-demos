---
title: Rapid incident resolution
  300-level live demo
description: Rapid incident resolution 300-level live demo
tabs: [ 'Demo preparation', 'Demo script']
---

export const Title = () => (
  <span>
    Rapid incident resolution <br/> 300-level live demo
  </span> );

<span id="place1"></span>

![banner](./images/AIOps_Observability_300_Script.jpg)

<details>
<summary>Introduction</summary>
<br/>

**Narration**: In this demo, I’ll show you how Cloud Pak for Watson AIOps helps SREs and IT Ops quickly identify, diagnose, and resolve incidents across mission-critical workloads.
<br/>
You’ll see how:<br/><br/>
-	Watson AIOps intelligently correlates multiple disparate sources of information such as logs, metrics, and events;<br/>
-	All of this information is condensed and presented in actionable alerts instead of large quantities of unrelated alerts; and<br/>
-	You can resolve a problem within seconds to minutes of being notified using Watson AIOps’ automation capabilities <br/><br/>
We will be using an application called Quote of the Day. It’s a content delivery app that serves up random quotations. The application is built on a microservices architecture and the services are running on Kubernetes.
<br/><br/>

**[Go to top](#place1)**

</details>

<details>

<summary>1 - Generate anomaly and discuss path to resolve incident without Watson AIOps</summary>

<br/>

| **1.1** | **Navigate to the Anomaly Generator and input sources** |
| :--- | :--- |
| **Actions** | Navigate to the **Anomaly Generator**<br/><br/>Choose “Rating service failure”<br/><br/>Click **start** |
| **Narration** | To see how this all works, I’m going to generate an anomaly in our application.  &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |
| **Screenshot** | <br/> ![Quote of the Day app](./images/quote-app.png) |
| **Action** | The anomaly generator will take a minute or so to start showing alerts in Slack<br/><br/> While it is running, navigate to the various input sources: Prometheus and ELK |
| **Narration** | Without Watson AIOps, we would get all sorts of alerts and notifications from multiple sources when a problem occurs.<br/><br/>Prometheus would start firing alerts, but we would have to look at them manually to find out if they are related.<br/><br/>Same with ELK – we might see new types of logs or errors coming in, but again it’s time consuming to determine the relationship. Hundreds of logs are streaming in every minute, making it very difficult for a human to keep up with them.<br/><br/>As we’ll see in a moment, with Watson AIOps, all of this information gets correlated and presented all in one place. This includes recommendations for how to resolve the incident. We can take action directly from the notification and resolve the incident quickly. &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |
| **Screenshots** | <br/> ![Prometheus](./images/prometheus.png) <br/>![Elastic](./images/elastic.png) |

<br/><br/>

**[Go to top](#place1)**

</details>

<details>

<summary>2 - Watson AIOps sends a notification that there’s a problem</summary>

<br/>

| **2.1** | **AIOps formats notification as story and adds affected services to it** |
| :--- | :--- |
| **Actions** | Story starts showing up in Slack |
| **Narration** | Notifications are now appearing in Slack. We’re using Slack in this demo, but Watson AIOps also integrates with Microsoft Teams.<br/><br/>Watson AIOps formats the notifications into a “story” using AI to correlate events, metrics, alerts, and logs. Each story brings together the various notifications for all the affected services by the same underlying issue. Imagine if each piece of data presented in the story was a separate notification – we’d quickly be inundated with alerts. <br/><br/>The story is like a home base for action when a problem arises. Instead of manually correlating things across multiple different tools, it’s all right here immediately when the notification is received. <br/><br/>In addition to providing a highly contextualized view of the incident, it enables us to jump in-context to other point tools to explore further details. This helps eliminate tool silos and helps us restore service faster.<br/><br/>This story is telling us there’s a problem with the Rating service, which is one of the microservices in our Quote of the Day application (**Note**: sometimes a different service, like Web, will be affected first. Just adapt narration if so).<br/><br/>In the background, the AI has done the work for us and presents us with a curated view of relevant information. It shows which services are affected: the relevant events and alerts that are indicative of the symptoms of this problem; anomalies that Watson AIOps has found in the log files; and similar incidents that have occurred in the past so we can see how they were successfully resolved. We’ll explore each of these components in more detail.<br/><br/>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |
| **Screenshot** | <br/> ![Finding root cause](./images/incident-title.png) |
| **Actions** | Additional affected services are added to the story |
| **Narration** | When this story first appeared, the only affected service was the Rating service [or whichever service was first affected].<br/><br/>Watson AIOps updates the stories in real time as more information comes in and gets correlated to this story. <br/><br/>So now we can see that in addition to Rating, the Web service is also affected. This is now even more critical since the Web service is the customer-facing front-end of the application, and we need to ensure that users can still access the app.<br/><br/>We need to find the root cause and fix this problem as quickly as possible.<br/><br/>
| **Screenshot** | <br/> ![Component](./images/component.png) |

**[Go to top](#place1)**

</details>

<details>

<summary>3 - Determining which service caused the problem</summary>

<br/>

| **3.1** | **Review notification to learn about issue** |
| :--- | :--- |
| **Action** | Scroll to “relevant events” section of story |
| **Narration** | We need to find out where the issue began so we can fix the problem and prevent it spreading further throughout the application.<br/><br/> Instead of having to go to Prometheus or another tool to look at the alerts, we can see them right here from the notification. Watson AIOps has determined that these events are related to each other and provides an explanation for how it determined these relationships right here in the notification. We can see that there are two groups of events based on related resources and the timing of the events.<br/><br/>
| **Screenshot** | <br/> ![Relevant events](./images/relevant-events.png) |
| **Action** | Click the **relevant events** button at bottom of the notification<br/><br/>A pop-up will appear with the grouped events<br/>
| **Narration** | We can inspect the grouped events right here, without searching for them in another tool.<br/><br/>It looks like the memory and CPU on the Rating service increased significantly. This is causing a significant slow-down in response time on both the Rating and Web services.<br/><br/>Based on this information, it seems that the Rating service is the source of the issue. But let’s get a bit more detail – this time from the log files.<br/><br/>
| **Screenshots** | <br/> ![View relevant events](./images/view-relevant-events.png) <br/>![Relevant events alerts](./images/relevant-events-alerts.png) |
| **Action** | Scroll down past the alerts to show **log anomalies** |
| **Narration** | Instead of needing to go to Kibana and manually sort through the hundreds or thousands of log entries that come in every minute, Watson AIOps has found several anomalies in the log files and presented them here. It trains on the log files of the application when it’s operating normally, and continually monitors for deviations from that baseline.<br/><br/>We can see that the anomalies are occurring on the Rating service, which fits with what we saw in the alerts. |
| **Screenshot** | <br/> ![Rating service](./images/rating-service.png) |
| **Action** | Click on “show more” |
| **Narration** | Watson AIOps gives us additional context on the anomaly. In this case, the “unknown_error” anomaly is telling us that Watson AIOps has never seen this type of log before (hence the “unknown”) and that the log message indicates there is some type of error. Watson AIOps is not only looking at the statistical frequency of the type of log, but it is also analyzing the words in the log message to give additional context (in this case that there’s likely an error).<br/><br/>Watson AIOps also explains why the anomaly was flagged. It expected to see 0 of this type of log, but it actually saw 4.<br/><br/> Now we know that there is a new type of log coming from the Rating service, and it’s indicating an error. <br/><br/>This further reinforces what we saw with the alerts -  it looks like the Rating service is likely the root of this problem.<br/><br/>
| **Screenshots** | <br/> ![anomaly](./images/anomaly.png) <br/>![anomaly 2](./images/log-anomaly-1.png) |
| **Action** | For the “unknown_error” anomaly, click “preview logs” |
| **Narration** | We can even preview the log messages that caused Watson AIOps to find the anomaly. |
| **Screenshots** | <br/> ![Preview logs](./images/preview-logs.png) <br/> ![Log preview](./images/log-preview.png) |

**[Go to top](#place1)**

</details>

<details>

<summary>4 - Getting resolution recommendations</summary>

<br/>

| **4.1** | **Watson AIOps searches simialr incidents for recommendations** |
| :--- | :--- |
| **Actions** | Close the log anomaly pop-up<br/><br/>Click on “similar incidents” button<br/><br/>Type “rating” into the search box |
| **Narration** | Now that we understand a bit more about what’s going on, we need to focus on our main goal: resolving the incident as quickly as possible.<br/><br/>Watson AIOps also brings in similar incidents and information regarding how they were resolved. This enhances operational efficiency by leveraging institutional knowledge that may be time consuming to find otherwise.<br/><br/>Since the alerts seem to point to the Rating service as having the memory and CPU increases, we’ll search for incidents that happened with that service. <br/><br/>Watson AIOps found two similar incidents. The first one seems like what we’re experiencing: Rating service is overheating and slowing. Using Natural Language Processing, Watson AIOps even went through the comments on the incident and highlighted key relevant information for us – in this case that the incident was resolved by running a runbook.<br/><br/>If we can use the same runbook to resolve the current incident it will make our job that much easier and restore service even faster! |
| **Screenshots** | <br/> ![Search similar incidents](./images/search-similar-incidents.png) <br/>![Search similar incidents - Rating](./images/search-similar-incidents-rating.png) <br/>![Search results](./images/search-results.png) |
| **Actions** | Click on the link for the first similar incident “Rating service overheating and slowing”<br/><br/>It will open a window in GitLab<br/><br/>If needed, sort comments “newest to oldest” |
| **Narration** | The description for this incident sounds a lot like what we are observing right now. The Rating service is stressed, with increases in CPU, memory, and latency. It’s also affecting the Web service.<br/><br/>The comment says there is a runbook that resolved this issue. This is very useful information that may have taken a long time to find out just by searching or asking colleagues. Watson AIOps helped us find this info very quickly. |
| **Screenshots** | <br/> ![Newest first](./images/newest-first.png)  |

**[Go to top](#place1)**

</details>

<details>

<summary>5 - Fixing the problem and restoring service</summary>

<br/>

| **5.1** | **View Event Manager to determine root cause and fix problem** |
| :--- | :--- |
| **Actions** | Navigate to **Event Manager (NOI)**<br/><br/>Click on **Events** in the sidebar menu<br/><br/>The top event should show a red circle (**critical**)<br/><br/>Click the down arrow to expand it |
| **Narration** | This is the Event Manager component of Watson AIOps. Here’s the event group that we’re working on. There are four events grouped together – these are the same ones we previewed earlier from the Slack notification. There’s additional detail here, including the likelihood of each event being the root cause of the overall issue and if there is a runbook associated with the event.<br/><br/>There are three events that occurred on the Rating service. They’re all rated as 99% likely to be the root cause – meaning that the Rating service is the source of the problem.<br/><br/>It also shows us that there’s a runbook associated with these events, which is what was mentioned in the GitLab incident comment. |
| **Screenshots** | <br/> ![Events1](./images/events1.png) <br/> ![Events2](./images/events2.png) |
| **Actions** | Click the dot in the runbook column<br/><br/>Run the runbook
| **Narration** | Now we’ll use the runbook that resets the Rating service. It should fix the problem. |
| **Screenshots** | <br/> ![Events3](./images/events3.png) <br/>![runbook1](./images/runbook1.png) <br/> ![Runbook2](./images/runbook2.png) |
| **Actions** | Navigate to **Instana**<br/><br/>Click on the **Summary** tab<br/><br/>Set time period to “last 15 minutes” and click the “Live” button [you will be showing the latency before, during, and after the incident] |
| **Narration** | To check that the runbook is fixing the problem, we can look at the health metrics in Instana. We’ll set the time period so we can see data from when the incident began until now.<br/><br/>We can see the latency of the application started increasing when the problem began. Now that we’ve run the runbook, it is going back down again. This confirms that the runbook was successful.
| **Narration** | Now we’ll this runbook that resets the Rating service. It should fix the problem. |
| **Screenshot** | <br/> ![runbook success](./images/runbook-success.png) |

**[Go to top](#place1)**

</details>

<details>

<summary>6 - Rating the runbook and closing out the incident</summary>

<br/>

| **6.1** | **Track success, review potential automation options, and close incident** |
| :--- | :--- |
| **Actions** | Go back to NOI Runbook screen<br/><br/>If you navigated away from it, get back with these steps:<br/><br/>Automations -> Runbooks -> click three dots at far right for the “Reset Rating Service” runbook -> Choose “view history” -> Click resume on most recent<br/><br/>Scroll down to bottom where there are stars/rating |
| **Narration** | We can rate the runbook to preserve the information that it was successful – this will be helpful for the next person who comes along looking at this runbook, as well as feedback to the author of the runbook. <br/><br/>This enables a collaborative approach to organically improve incident resolution over time. As the system matures it can evolve into an increasingly automated self-healing system. |
| **Screenshot** | <br/> ![runbook worked](./images/runbook-worked.png) |
| **Actions** | Click the **Information** tab on right<br/><br/>Scroll down to see the star rating and success rate (should be 5 stars and 100%) |
| **Narration** | Since this runbook worked and resolved our problem, and we know a similar problem has happened before, perhaps it’s a good candidate for automation. <br/><br/>We can see that it has a 5-star rating and 100% success rate. Before we automate it, let’s check that this isn’t only due to having a small sample size. |
| **Screenshots** | <br/> ![Fix ratings](./images/runbook-fix-ratings1.png) <br/> ![Fix ratings 2](./images/runbook-fix-ratings2.png) |
| **Actions** | Go to Automation on left-hand sidebar menu<br/><br/>Choose Runbooks<br/><br/>Click three dots on far right for the “Fix Rating Service Failure” runbook<br/><br/>Choose “View History” |
| **Narration** | In the history for this runbook, we can see it’s been run 52 times and had zero failures. That’s a very good track record and we should consider automating this process! We’ll recommend automation at the next team standup. |
| **Screenshots** | <br/> ![Runbook automations](./images/runbook-automations.png) <br/> ![Runbook view history](./images/runbook-view-history.png) <br/> ![Runbook executions](./images/runbook-executions.png) |
| **Actions** | Navigate to **Slack**<br/><br/>Add the resolution rec that was followed to the story by clicking the “add to story” button |
| **Narration** | Now we are ready to close out the incident. <br/><br/>We found the runbook because it was mentioned in the similar incident, so we want to preserve that information. To do so, we can click “add to story” and Watson AIOps adds a comment with the information about the similar incident.<br/><br/> This keeps all the information in one place so it’s easy to find later or if another similar incident occurs in the future. |
| **Screenshot** | <br/> ![Search results Story 695](./images/search-results-story-695.png) |
| **Actions** | At bottom of the story notification, click “acknowledge”<br/><br/>Choose “keep in channel” and “close”<br/><br/> Optionally add a comment such as “executed runbook to fix issue,” then click “acknowledge” |
| **Narration** | Then we will acknowledge the incident and mark it as closed. Watson AIOps archives all the information from the incident in the comments of the original message. So we can go back to it whenever needed to see exactly what happened and how it was fixed. |
| **Screenshot** | <br/> ![acknowledge](./images/acknowledge.png) <br/> ![closed](./images/closed.png) |

**[Go to top](#place1)**

</details>

<details>

<summary>Summary</summary>

<br/>
Using Watson AIOps we were able to quickly resolve the incident without manually correlating information or needing to jump among many different tools. This streamlined process even led us to find a possibility for further automation and time saving in the future.
<br/><br/>

**[Go to top](#place1)**

</details>
